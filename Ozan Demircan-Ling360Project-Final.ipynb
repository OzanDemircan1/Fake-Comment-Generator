{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Fake Comment Generator Using Reddit Corpus\n",
        "\n",
        "All the work for this program was done by Ozan Demircan.\n"
      ],
      "metadata": {
        "id": "dXyYAr5zYlyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading and reading the corpus from the subreddit r/NeutralPolitics using ConvoKit toolkit\n",
        "\n",
        "!pip install convokit --quiet\n",
        "\n",
        "\n",
        "from convokit import Corpus, download\n",
        "\n",
        "corpus = Corpus(filename=download(\"subreddit-NeutralPolitics\"))\n",
        "corpus.print_summary_stats()\n"
      ],
      "metadata": {
        "id": "cbHFEYyD4amk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78cfac24-fe41-422d-a092-54431add295b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already exists at /root/.convokit/downloads/subreddit-NeutralPolitics\n",
            "Number of Speakers: 41204\n",
            "Number of Utterances: 434685\n",
            "Number of Conversations: 14676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Cleaning and Tokenizing the Corpus\n",
        "\n",
        "tokens = []\n",
        "i=30000\n",
        "for utt in corpus.iter_utterances():\n",
        "    i -= 1\n",
        "    comment_tokenized = []\n",
        "    sentences = sent_tokenize(utt.text)\n",
        "    if(utt.text != \"[Deleted]\" and utt.text != \"[Removed]\"):\n",
        "        for s in sentences:\n",
        "            s_tokenized = word_tokenize(s)\n",
        "            tokens += [\"<s>\"]+s_tokenized+[\"</s>\"]\n",
        "        if(i==0):\n",
        "            break\n",
        "\n",
        "# We need everything in lower case for Gensim to work\n",
        "tokens = [i.lower() for i in tokens]\n",
        "print(tokens[:100]) "
      ],
      "metadata": {
        "id": "2jOdLw6m57MR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff0cbf1-abcb-4c81-b0c0-b4c093da53a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'i', 'was', 'reading', 'this', 'article', '[', 'here', ']', '(', 'http', ':', '//rt.com/usa/obama-syria-chemical-weapons-634/', ')', ',', 'where', 'president', 'obama', 'announced', 'that', 'there', 'is', 'evidence', 'that', 'a', 'chemical', 'agent', 'has', 'been', 'used', 'in', 'syria', ',', 'and', 'then', 'i', 'remembered', 'reading', 'an', 'article', 'earlier', 'that', 'said', 'officials', 'from', 'germany', 'were', 'asking', 'to', 'see', 'the', 'proof', 'that', 'the', 'americans', 'had', '.', '</s>', '<s>', 'i', \"'m\", 'not', 'trying', 'to', 'directly', 'compare', 'the', \"'proofs\", \"'\", 'stated', ',', 'be', 'more', 'that', 'maybe', 'this', 'proof', 'of', 'chemical', 'warfare', 'is', 'just', 'a', 'ruse', 'to', 'justify', 'a', 'more', 'predominant', 'role', 'of', 'intervention', 'in', 'the', 'syrian', 'situation', ',', 'much', 'like', 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to Generate the Comments\n",
        "\n",
        "def CommentGenerator(max_token_count=200, starter = \"\"):\n",
        "\n",
        "    comment = \"\"\n",
        "    from itertools import chain \n",
        "    from scipy import stats\n",
        "    import re\n",
        "\n",
        "    comment += \"<s>\"\n",
        "    current_phrase = (\"<s>\",starter)\n",
        "    trigrams = [((tokens[i],tokens[i+1]), tokens[i+2]) for i in range(len(tokens)-2)]\n",
        "    trigram_cfd = nltk.ConditionalFreqDist(trigrams)\n",
        "    trigram_pbs = nltk.ConditionalProbDist(trigram_cfd, nltk.MLEProbDist)\n",
        "    for i in range(max_token_count+1):\n",
        "      comment += current_phrase[1] + \" \"\n",
        "      probable_words = list(trigram_pbs[current_phrase].samples())\n",
        "      word_probabilities = [trigram_pbs[current_phrase].prob(word) for word in probable_words]\n",
        "      if not word_probabilities:\n",
        "        return \"Possible trigram not found!\"\n",
        "      result = stats.multinomial.rvs(1,word_probabilities)\n",
        "      index_of_probable_word = list(result).index(1)\n",
        "      current_phrase = (current_phrase[1],(probable_words[index_of_probable_word]))\n",
        "      \n",
        "    comment = re.sub(\"<s>\", \"\", comment)\n",
        "    comment = re.sub(\"</s>\", \"\", comment)  \n",
        "    \n",
        "    return comment"
      ],
      "metadata": {
        "id": "0WA900DPK6z9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Gensim and downloading a ready dataset\n",
        "\n",
        "import gensim.downloader\n",
        "glove_vectors = gensim.downloader.load('glove-twitter-25')"
      ],
      "metadata": {
        "id": "1oI0k2mOMZoV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting related keywords using Gensim and calling the function to generate the comments\n",
        "input_text = input(\"Enter the topic you want comments on:\")\n",
        "most_related = glove_vectors.most_similar(input_text)\n",
        "keywords = [keyword[0] for keyword in most_related[:5]]\n",
        "print(keywords)\n",
        "example_comments = [CommentGenerator(max_token_count=50, starter = keyword) for keyword in keywords]\n",
        "print(example_comments)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_nEeqb9JW2e",
        "outputId": "71f28fc2-76f0-47bb-ad61-a74afea5e1cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the topic you want comments on:senate\n",
            "['labour', 'congressional', 'parliament', 'congress', 'immigration']\n",
            "[\"labour holds .   the government in regulation of the problems fairly easily solved , but so far does the current healthcare controversy in america .   the fcc 's recent actions ?   it 's about offering causal explanations for the government take a few months ? \", \"congressional spending on programs like this simply a modernization of politicking , not the school system , if i concede in your criticism .   i 'm not familiar with its state of mind for as little as he resigned it to washington after the event .   what \", 'Possible trigram not found!', \"congress has created a huge push across the board of directors funded people that have a limited number of agencies have to get firearms if they did n't understand what we see populists elected in over 70 years and a license to have opinions and opinions into the healthcare problem , \", 'immigration policy be ?   no one will be .   & gt ; the actual measured value of a bias in an environment conducive to people for interest .   * the same evidence supporting full legalization would benefit from sending out ss checks , waiting periods ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grammar Correction\n",
        "\n",
        "!pip install --quiet GingerIt\n",
        "\n",
        "from gingerit.gingerit import GingerIt\n",
        "\n",
        "# Creating a GingerIt instance\n",
        "parser = GingerIt()\n",
        "\n",
        "# Defining a function to check the grammar of a sentence and return the corrected sentence\n",
        "def check_grammar(sentence):\n",
        "    result = parser.parse(sentence)\n",
        "    corrected_sentence = result['result']\n",
        "    return corrected_sentence\n",
        "\n",
        "corrected_comments = []\n",
        "for comment in example_comments:\n",
        "    corrected_sentence = check_grammar(comment)\n",
        "    print(\"Corrected sentence:\", corrected_sentence)\n",
        "    corrected_comments.append(corrected_sentence)\n",
        "\n",
        "example_comments = corrected_comments"
      ],
      "metadata": {
        "id": "E5qrQf58CK4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2daf377-3a0f-49e1-d1e2-30dbb784b592"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrected sentence: Labor holds.   The government in the regulation of the problems fairly easily solved, but so far does the current health care controversy in America.   The FCC 's recent actions?   It's about offering causal explanations for the government takes a few months? \n",
            "Corrected sentence: Congressional spending on programs like this simply a modernization of politicking, not the school system, if I concede in your criticism.   I 'm not familiar with its state of mind for as little as he resigned it to Washington after the event.   What \n",
            "Corrected sentence: Possible trigram not found!\n",
            "Corrected sentence: congress has created a huge push across the board of directors funded people that have a limited number of agencies have to get firearms if they didn't understand what we see populists elections in over 70 years and a license to have opinions and opinions into the healthcare problem, \n",
            "Corrected sentence: Immigration policy is?   No one will be.   & get; the actual measured value of a bias in an environment conducive to people of interest.   * the same evidence supporting full legalization would benefit from sending out SS checks, waiting periods \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the necessary resources for sentiment analysis\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNZC2dPdRun2",
        "outputId": "9e6c2312-f31f-4248-e7c2-bab23d2922fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a function to analyze the positivity of a comment\n",
        "def analyze_positivity(text):\n",
        "    scores = sia.polarity_scores(text)\n",
        "    return scores"
      ],
      "metadata": {
        "id": "0PXz1a7YR2Uk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the comments using a Sentiment analyzer in NLTK\n",
        "\n",
        "sentiment_scores = [analyze_positivity(text) for text in example_comments]\n",
        "print(sentiment_scores)\n",
        "for i in range(len(sentiment_scores)):\n",
        "    if (sentiment_scores[i][\"compound\"] > 0):\n",
        "      print(i,\":\",example_comments[i],\":Comment is positive.\")\n",
        "    elif(sentiment_scores[i][\"compound\"] < 0):\n",
        "      print(i,\":\",example_comments[i],\":Comment is negative.\")\n",
        "    else:\n",
        "      print(i,\":\",example_comments[i],\":Comment is neutral.\")"
      ],
      "metadata": {
        "id": "kiCe619KLPfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65109051-ad97-4ee3-f797-317a529462b5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'neg': 0.04, 'neu': 0.787, 'pos': 0.173, 'compound': 0.7236}, {'neg': 0.105, 'neu': 0.838, 'pos': 0.057, 'compound': -0.2815}, {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}, {'neg': 0.09, 'neu': 0.801, 'pos': 0.109, 'compound': 0.0}, {'neg': 0.078, 'neu': 0.675, 'pos': 0.246, 'compound': 0.8271}]\n",
            "0 : Labor holds.   The government in the regulation of the problems fairly easily solved, but so far does the current health care controversy in America.   The FCC 's recent actions?   It's about offering causal explanations for the government takes a few months?  :Comment is positive.\n",
            "1 : Congressional spending on programs like this simply a modernization of politicking, not the school system, if I concede in your criticism.   I 'm not familiar with its state of mind for as little as he resigned it to Washington after the event.   What  :Comment is negative.\n",
            "2 : Possible trigram not found! :Comment is neutral.\n",
            "3 : congress has created a huge push across the board of directors funded people that have a limited number of agencies have to get firearms if they didn't understand what we see populists elections in over 70 years and a license to have opinions and opinions into the healthcare problem,  :Comment is neutral.\n",
            "4 : Immigration policy is?   No one will be.   & get; the actual measured value of a bias in an environment conducive to people of interest.   * the same evidence supporting full legalization would benefit from sending out SS checks, waiting periods  :Comment is positive.\n"
          ]
        }
      ]
    }
  ]
}